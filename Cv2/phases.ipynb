{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35a5b96b-0285-4ba3-8df9-1058761c5475",
   "metadata": {},
   "source": [
    "#  Phase 4: Working with Video & Webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e31166d6-7a27-4e70-957d-904ee87c7c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b592ba13-f185-426c-b030-912d2d62a2cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting .....\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # return True/False  frame = image\n",
    "\n",
    "    if not ret:\n",
    "        print('Could not read frame')\n",
    "        break\n",
    "    cv2.imshow('Webcam Feed',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print('Quitting .....')\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef709642-8239-4da7-9908-ebe156edf3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quitting .....\n"
     ]
    }
   ],
   "source": [
    "camera = cv2.VideoCapture(0)\n",
    "frame_width = int(camera.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(camera.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "codec = cv2.VideoWriter_fourcc(*'XVID')\n",
    "recorder = cv2.VideoWriter('my_video.avi',codec,20,(frame_width,frame_height))\n",
    "\n",
    "while True:\n",
    "    success,image = camera.read()\n",
    "    if not success:\n",
    "        break\n",
    "    recorder.write(image)\n",
    "    cv2.imshow('Recording Video',image)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        print('Quitting .....')\n",
    "        break\n",
    "camera.release()\n",
    "recorder.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "600aa1e3-f708-416f-ab53-9446b49bbabc",
   "metadata": {},
   "source": [
    "#  Phase 5: Image Filtering & Blurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecee22a1-b6ed-48dd-9ab7-d23a123fa418",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('nature_tree.jpg')\n",
    "blurred = cv2.GaussianBlur(image,(7,7),3)\n",
    "\n",
    "cv2.imshow('Original image',image)\n",
    "cv2.imshow('Blurred image',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96a3991b-2bf1-4531-bc55-54636c29dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.medianBlur(image,5)\n",
    "\n",
    "cv2.imshow('Original',image)\n",
    "cv2.imshow('clean image',blurred)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2f4b0f-a1bd-49ca-872b-8e83d3b191f8",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "image = cv2.imread('camel.jpg')\n",
    "sharpen_kernel = np.array([ \n",
    "    [0,-1,0],\n",
    "    [-1,5,-1],\n",
    "    [0,-1,0]\n",
    "]) \n",
    "sharpened = cv2.filter2D(image,-1,sharpen_kernel)\n",
    "cv2.imshow('Original image',image)\n",
    "cv2.imshow('Sharpened image',sharpened)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198d73a6-4d28-4548-ba91-598edd1a9ed8",
   "metadata": {},
   "source": [
    "# Phase 6: Edge Detection & Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08aa9407-5617-4bdc-8137-03d7f9a7291d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('flower.png',cv2.IMREAD_GRAYSCALE)\n",
    "edges = cv2.Canny(img,50,150)\n",
    "cv2.imshow('Original image',img)\n",
    "cv2.imshow('Edges',edges)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86f2e3f7-db10-4890-a8f1-111513b9b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('man.png',cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "ret, thresh_img = cv2.threshold(img,120,255,cv2.THRESH_BINARY)\n",
    "cv2.imshow('Original image',img)\n",
    "cv2.imshow('Threshold image',thresh_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d8482-af1a-4544-af4d-196ca05c4d17",
   "metadata": {},
   "source": [
    "### bitwise operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c112b9-384e-4046-9fc2-fb02806b83fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "1- cv2.bitwise_and(img1,img2)\n",
    "2- cv2.bitwise_or(img1,img2)\n",
    "3- cv2.bitwise_not(img1)\n",
    "\n",
    "* image height width same\n",
    "** use only black & white\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ea43ad4-a2ca-4dbc-aad5-326e6c2bd5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img1 = np.zeros((300,300))\n",
    "img2 = np.zeros((300,300))\n",
    "# print(img1)\n",
    "cv2.circle(img1,(150,150),100,255,-1)\n",
    "cv2.rectangle(img2,(100,100),(250,250),255,-1)\n",
    "\n",
    "bitwise_and =  cv2.bitwise_and(img1,img2)\n",
    "bitwise_or = cv2.bitwise_or(img1,img2)\n",
    "bitwise_not = cv2.bitwise_not(img1)\n",
    "\n",
    "cv2.imshow('Circle',img1)\n",
    "cv2.imshow('Rectangle',img2)\n",
    "cv2.imshow('AND',bitwise_and)\n",
    "cv2.imshow('OR',bitwise_or)\n",
    "cv2.imshow('NOT',bitwise_not)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e9ec9e-b0d2-46dd-93ed-f9cf25a6f4f2",
   "metadata": {},
   "source": [
    "#  Phase 7: Contours & Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea533683-90de-4862-ac52-729aaf42e9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('shape.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) # first convert into grayscale\n",
    "_, thresh = cv2.threshold(gray, 200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "contours, heirarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "\n",
    "cv2.imshow('Countours',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df2a8a2f-34c5-4490-8a08-4dcb9894218f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('circle.png')\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "_, thresh = cv2.threshold(gray, 200,255,cv2.THRESH_BINARY)\n",
    "\n",
    "contours, heirarchy = cv2.findContours(thresh,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "cv2.drawContours(img,contours,-1,(0,255,0),3)\n",
    "for contour in contours:\n",
    "    approx = cv2.approxPolyDP(contour,0.01 * cv2.arcLength(contour,True),True)\n",
    "\n",
    "    corners = len(approx)\n",
    "\n",
    "    if corners == 3:\n",
    "        shape_name = \"Triangle\"\n",
    "    elif corners == 4:\n",
    "        shape_name = \"Rectangle\"\n",
    "    elif corners == 5:\n",
    "        shape_name = \"Pentagon\"\n",
    "    elif corners > 5:\n",
    "        shape_name = \"Circle\"\n",
    "    else:\n",
    "        shape_name = \"Unknown\"\n",
    "\n",
    "    cv2.drawContours(img,[approx],0,(0,255,0),2)\n",
    "    x = approx.ravel()[0] #top-left location\n",
    "    '''\n",
    "    [\n",
    "    [[100,200]],\n",
    "    [[150,250]],\n",
    "    [[120,270]],\n",
    "    ]\n",
    "\n",
    "    [100,200,150,250,,120,270]\n",
    "    '''\n",
    "    y = approx.ravel()[1]-10\n",
    "    \n",
    "    cv2.putText(img,shape_name,(x,y),cv2.FONT_HERSHEY_COMPLEX,0.6,(255,0,0), 2)\n",
    "cv2.imshow('Countours',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60337f15-c0a8-41df-a56d-69e22b95c9c9",
   "metadata": {},
   "source": [
    "# Phase 8: Face & Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5abbf739-eb0f-42aa-8fe5-bdc3700b8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True: \n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,5)\n",
    "\n",
    "    \"\"\"\n",
    "    detectMultiScale() - scan & detect faces\n",
    "    1.1 balance, not too slow, blind\n",
    "\n",
    "    minNeighbors = 5\n",
    "    \"\"\"\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    \"\"\"\n",
    "    x,y - top=left corner    right-bottom(x+w, y+h)\n",
    "    face = [\n",
    "    (100,150,80,80) face1\n",
    "    (250,120,90,90) face2\n",
    "    ]\n",
    "    x - how far from left\n",
    "    y - how far from top\n",
    "    w - width of face\n",
    "    h - height of face\n",
    "    \"\"\"\n",
    "    cv2.imshow('Webcam Face Detection',frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cd1ea1-9026-4bea-b0a1-0e172e8931da",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "smile_cascade = cv2.CascadeClassifier('haarcascade_smile.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray,1.1,5)\n",
    "\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "\n",
    "        roi_gray = gray[y:y+h,x:x+w] # rangion of intrest\n",
    "        roi_color = frame[y:y+h,x:x+w]\n",
    "\n",
    "        eyes = eye_cascade.detectMultiScale(roi_gray,1.1,10)\n",
    "        if len(eyes) > 0:\n",
    "            cv2.putText(frame,\"Eyes Detected\",(x,y-30),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,255),2)\n",
    "\n",
    "        smiles = smile_cascade.detectMultiScale(roi_gray,1.7,20)\n",
    "        if len(smiles) > 0:\n",
    "            cv2.putText(frame,\"Smiles Detected\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.6,(0,0,254),2)\n",
    "\n",
    "        cv2.imshow(\"Smart Face Detection\",frame)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.deatroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eedab670-0e77-4816-b096-e67907a0ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "haarcascade_xml_files = 'https://github.com/opencv/opencv/tree/master/data/haarcascades'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
